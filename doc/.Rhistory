"tm",  "beeswarm","RColorBrewer",
"topicmodels","plyr","ggplot2","wordcloud","reshape2","tidytext","stringr","qdap","cowplot","tidyr")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(tm)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(topicmodels)
library(reshape2)
library(tidytext)
library(stringr)
library(qdap)
library(beeswarm)
library(shiny)
library(cowplot)
library(tidyr)
library(udunits2)
# Chunk 3
print(R.version)
# Chunk 4
path<-file.path("..","data","InauguralSpeeches")
filenames<-dir(path)
speeches.number<-length(dir(path))
speeches.number
docs<-Corpus(DirSource(path))
head(summary(docs),3)
# Chunk 5
years<-read.csv("../data/InauguationDates.csv",header=TRUE,stringsAsFactors = FALSE)
years.name<-gsub("[ |.]","",years$PRESIDENT)
years.recession<-c(1825,1837,1847,1857,1866,1873,1882:1893,1920,1929:1933,1948:1949,1953:1954,1957:1958,1960:1961,1969:1970,1973:1975,1980:1982,1990:1991,2001:2002,2007:2009)
whether.res<-rep(FALSE,58)
for (i in 1:58) {
n<-nchar(filenames[i])
filenames1<-substr(filenames[i],6,n-6)
j<-which(years.name==filenames1)
time<-years[j,as.numeric(substr(filenames[i],n-4,n-4))+1]
m<-nchar(time)
if (sum(as.numeric(substr(time,m-3,m)) == years.recession) > 0) whether.res[i]<-TRUE
}
sum(whether.res)
58-sum(whether.res)
# Chunk 6
docs<-tm_map(docs,content_transformer(tolower))
text.count<-function(speeches){
text<-speeches[[1]]
punc<-length(gregexpr("[.|!|?|;]",text)[[1]])
i<-length(gregexpr("i |me |myself |my |mine ",text)[[1]])
we<-length(gregexpr("we |us |ourself|our |ours ",text)[[1]])/i
modal<-length(gregexpr("will|can|shall|must",text)[[1]])/i
return(list(sentence=punc,i=i,we=we,modal=modal))
}
docs<-tm_map(docs,removeNumbers)
docs<-tm_map(docs,stripWhitespace)
text.num<-llply(docs,text.count)
text.num<-ldply(text.num,unlist)
text.num$whether.res<-whether.res
beeswarm(sentence~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2, xlab="whether speech making during a recession",ylab="Number of sentences.")
boxplot(sentence~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
# Chunk 7
beeswarm(we~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="the proportion of we to i")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
# Chunk 8
beeswarm(modal~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="Number of modals")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
# Chunk 9
docs.res<-data.frame(stringsAsFactors = FALSE)
docs.nres<-data.frame(stringsAsFactors = FALSE)
for(i in 1:58){
docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
docs[[i]][[4]]<-word_count(docs[[i]][[3]])
docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
docs[[i]][[3]]$speech.num<-rep(i,nrow(docs[[i]][[3]]))
docs[[i]][[5]]<-unnest_tokens(docs[[i]][[3]],word,text)
if (whether.res[i]) docs.res<-rbind(docs.res,docs[[i]][[3]])
else docs.nres<-rbind(docs.nres,docs[[i]][[3]])
}
docs.res.word<-unnest_tokens(docs.res,word,text)
docs.nres.word<-unnest_tokens(docs.nres,word,text)
par(mfrow=c(1,2))
docs.res.word %>%
inner_join(get_sentiments("bing")) %>%
count(word,sentiment,sort=TRUE) %>%
acast(word~sentiment,value.var="n",fill=0) %>%
comparison.cloud(colors=c("#E69F00", "#56B4E9"),max.words=100,title.size=2)
legend("topleft",legend="recession",bty="n",text.col=1)
docs.nres.word %>%
inner_join(get_sentiments("bing")) %>%
count(word,sentiment,sort=TRUE) %>%
acast(word~sentiment,value.var="n",fill=0) %>%
comparison.cloud(colors=c("#E69F00", "#56B4E9"),max.words=100,title.size=2)
legend("topleft",legend="not recession",bty="n",text.col=1)
# Chunk 10
bingword.res<-docs.res.word %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bingword.nres<-docs.nres.word %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
a<-bingword.res %>%
group_by(sentiment) %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment(recession)",
x = NULL) +
coord_flip()
b<-bingword.nres %>%
group_by(sentiment) %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment( not recession)",
x = NULL) +
coord_flip()
plot_grid(plotlist=list(a,b),nrow=2)
# Chunk 11: eruptions
inputPanel(
selectInput("i", label = "Speeches in the recession",
choices = filenames[whether.res], selected = filenames[whether.res][1]),
sliderInput("adjust", label = "number of word",
min = 50, max = 150, value = 100, step = 10),
selectInput("j", label = "Speeches not in the recession",
choices = filenames[!whether.res], selected = filenames[!whether.res][1])
)
renderPlot({
par(mfrow=c(1,2),mar = c(1,1,1,1))
docs[[which(input$i==filenames)]][[5]] %>%
inner_join(get_sentiments("nrc")) %>%
count(word,sentiment,sort=TRUE) %>%
acast(word~sentiment,value.var="n",fill=0) %>%
comparison.cloud(colors=c("#999999","#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#C77CFF","#F8766D","#7CAE00"),max.words=as.numeric(input$adjust),title.size=2)
docs[[which(input$j==filenames)]][[5]] %>%
inner_join(get_sentiments("nrc")) %>%
count(word,sentiment,sort=TRUE) %>%
acast(word~sentiment,value.var="n",fill=0) %>%
comparison.cloud(colors=c("#999999","#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#C77CFF","#F8766D","#7CAE00"),max.words=as.numeric(input$adjust),title.size=2)
})
# Chunk 12
speech.res.word<-docs.res.word %>%
count(speech.num,word, sort = TRUE) %>%
ungroup()
speech.res.word<-left_join(speech.res.word,(speech.res.word%>%group_by(speech.num)%>%summarize(total=sum(n))))
speech.res.word<-speech.res.word %>% bind_tf_idf(word,speech.num,n)
plot.res <- speech.res.word %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
a<-ggplot(plot.res[1:20,], aes(word, tf_idf)) +
geom_bar(stat = "identity") +
labs(x = NULL, y = "tf-idf") +
coord_flip()
speech.nres.word<-docs.nres.word %>%
count(speech.num,word, sort = TRUE) %>%
ungroup()
speech.nres.word<-left_join(speech.nres.word,(speech.nres.word%>%group_by(speech.num)%>%summarize(total=sum(n))))
speech.nres.word<-speech.nres.word %>% bind_tf_idf(word,speech.num,n)
plot.nres <- speech.nres.word %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
b<-ggplot(plot.nres[1:20,], aes(word, tf_idf)) +
geom_bar(stat = "identity") +
labs(x = NULL, y = "tf-idf") +
coord_flip()
plot_grid(plotlist=list(a,b))
# Chunk 13
count_bigrams <- function(dataset) {
dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE)
}
res_bigrams <- docs.res %>%
count_bigrams()
head(res_bigrams,12)
nres_bigrams <- docs.nres %>%
count_bigrams()
head(nres_bigrams,12)
# Chunk 14
docs<-tm_map(docs,removeWords,c(stopwords("english"),"us","will","can","shall","must","upon","may","people","great","states","one","let","government","nation","now","every","new"))
docs<-tm_map(docs,removePunctuation)
a<-1:58
docs.r<-docs[a[whether.res]]
docs.nr<-docs[a[!whether.res]]
dtmatrix.res<-DocumentTermMatrix(docs.r)
inaugu.r.lda<-LDA(dtmatrix.res,k=2)
inaugu.r.lda.td<-tidy(inaugu.r.lda)
inaugu.r.term<-inaugu.r.lda.td%>%
group_by(topic)%>%
top_n(10,beta)%>%
ungroup()%>%
arrange(topic,-beta)
inaugu.r.term %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
dtmatrix.nres<-DocumentTermMatrix(docs.nr)
inaugu.nr.lda<-LDA(dtmatrix.nres,k=2)
inaugu.nr.lda.td<-tidy(inaugu.nr.lda)
inaugu.nr.term<-inaugu.nr.lda.td%>%
group_by(topic)%>%
top_n(10,beta)%>%
ungroup()%>%
arrange(topic,-beta)
inaugu.nr.term %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
View(text.num)
beeswarm(we~whether.res,data = text.num[-44,],horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="the proportion of we to i")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
?labels
docs<-tm_map(docs,removeWords,c(stopwords("english"),"us","will","can","shall","must","upon","may","people","great","states","one","let","government","nation","now","every","new","america","american","world","free"))
docs<-tm_map(docs,removePunctuation)
a<-1:58
docs.r<-docs[a[whether.res]]
docs.nr<-docs[a[!whether.res]]
set.seed(1)
dtmatrix.res<-DocumentTermMatrix(docs.r)
inaugu.r.lda<-LDA(dtmatrix.res,k=2)
inaugu.r.lda.td<-tidy(inaugu.r.lda)
inaugu.r.term<-inaugu.r.lda.td%>%
group_by(topic)%>%
top_n(10,beta)%>%
ungroup()%>%
arrange(topic,-beta)
print("speeches in a recession")
inaugu.r.term %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
dtmatrix.nres<-DocumentTermMatrix(docs.nr)
inaugu.nr.lda<-LDA(dtmatrix.nres,k=2)
inaugu.nr.lda.td<-tidy(inaugu.nr.lda)
inaugu.nr.term<-inaugu.nr.lda.td%>%
group_by(topic)%>%
top_n(10,beta)%>%
ungroup()%>%
arrange(topic,-beta)
print("speeches not in a recession")
inaugu.nr.term %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
packages.used=c("tibble","udunits2",
"sentimentr", "dplyr",
"tm",  "beeswarm","RColorBrewer",
"topicmodels","plyr","ggplot2","wordcloud","reshape2","tidytext","stringr","qdap","cowplot","tidyr")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(tm)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(topicmodels)
library(reshape2)
library(tidytext)
library(stringr)
library(qdap)
library(beeswarm)
library(shiny)
library(cowplot)
library(tidyr)
library(udunits2)
# Chunk 3
print(R.version)
# Chunk 4
path<-file.path("..","data","InauguralSpeeches")
filenames<-dir(path)
speeches.number<-length(dir(path))
speeches.number
docs<-Corpus(DirSource(path))
head(summary(docs),3)
# Chunk 5
years<-read.csv("../data/InauguationDates.csv",header=TRUE,stringsAsFactors = FALSE)
years.name<-gsub("[ |.]","",years$PRESIDENT)
years.recession<-c(1825,1837,1847,1857,1866,1873,1882:1893,1920,1929:1933,1948:1949,1953:1954,1957:1958,1960:1961,1969:1970,1973:1975,1980:1982,1990:1991,2001:2002,2007:2009)
whether.res<-rep(FALSE,58)
for (i in 1:58) {
n<-nchar(filenames[i])
filenames1<-substr(filenames[i],6,n-6)
j<-which(years.name==filenames1)
time<-years[j,as.numeric(substr(filenames[i],n-4,n-4))+1]
m<-nchar(time)
if (sum(as.numeric(substr(time,m-3,m)) == years.recession) > 0) whether.res[i]<-TRUE
}
sum(whether.res)
58-sum(whether.res)
# Chunk 6
docs<-tm_map(docs,content_transformer(tolower))
text.count<-function(speeches){
text<-speeches[[1]]
punc<-length(gregexpr("[.|!|?|;]",text)[[1]])
i<-length(gregexpr("i |me |myself |my |mine ",text)[[1]])
we<-length(gregexpr("we |us |ourself|our |ours ",text)[[1]])/i
modal<-length(gregexpr("will|can|shall|must",text)[[1]])/i
return(list(sentence=punc,i=i,we=we,modal=modal))
}
docs<-tm_map(docs,removeNumbers)
docs<-tm_map(docs,stripWhitespace)
text.num<-llply(docs,text.count)
text.num<-ldply(text.num,unlist)
text.num$whether.res<-whether.res
beeswarm(sentence~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2, xlab="whether speech making during a recession",ylab="Number of sentences.")
boxplot(sentence~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
# Chunk 7
beeswarm(we~whether.res,data = text.num[-44,],horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="the proportion of we to i")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
# Chunk 8
beeswarm(modal~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="Number of modals")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
# Chunk 9
docs.res<-data.frame(stringsAsFactors = FALSE)
docs.nres<-data.frame(stringsAsFactors = FALSE)
for(i in 1:58){
docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
docs[[i]][[4]]<-word_count(docs[[i]][[3]])
docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
docs[[i]][[3]]$speech.num<-rep(i,nrow(docs[[i]][[3]]))
docs[[i]][[5]]<-unnest_tokens(docs[[i]][[3]],word,text)
if (whether.res[i]) docs.res<-rbind(docs.res,docs[[i]][[3]])
else docs.nres<-rbind(docs.nres,docs[[i]][[3]])
}
docs.res.word<-unnest_tokens(docs.res,word,text)
docs.nres.word<-unnest_tokens(docs.nres,word,text)
par(mfrow=c(1,2))
docs.res.word %>%
inner_join(get_sentiments("bing")) %>%
count(word,sentiment,sort=TRUE) %>%
acast(word~sentiment,value.var="n",fill=0) %>%
comparison.cloud(colors=c("#E69F00", "#56B4E9"),max.words=100,title.size=2)
legend("topleft",legend="recession",bty="n",text.col=1,cex = 2)
docs.nres.word %>%
inner_join(get_sentiments("bing")) %>%
count(word,sentiment,sort=TRUE) %>%
acast(word~sentiment,value.var="n",fill=0) %>%
comparison.cloud(colors=c("#E69F00", "#56B4E9"),max.words=100,title.size=2)
legend("topleft",legend="not recession",bty="n",text.col=1,cex = 2)
# Chunk 10
bingword.res<-docs.res.word %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bingword.nres<-docs.nres.word %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
a<-bingword.res %>%
group_by(sentiment) %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment (in a recession)",
x = NULL) +
coord_flip()
b<-bingword.nres %>%
group_by(sentiment) %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment (not in a recession)",
x = NULL) +
coord_flip()
plot_grid(plotlist=list(a,b),nrow=2)
# Chunk 11: eruptions
inputPanel(
selectInput("i", label = "Speeches in the recession",
choices = filenames[whether.res], selected = filenames[whether.res][1]),
sliderInput("adjust", label = "number of word",
min = 50, max = 150, value = 100, step = 10),
selectInput("j", label = "Speeches not in the recession",
choices = filenames[!whether.res], selected = "inaugDonaldJTrump-1.txt")
)
renderPlot({
par(mfrow=c(1,2),mar = c(1,1,1,1))
docs[[which(input$i==filenames)]][[5]] %>%
inner_join(get_sentiments("nrc")) %>%
count(word,sentiment,sort=TRUE) %>%
acast(word~sentiment,value.var="n",fill=0) %>%
comparison.cloud(colors=c("#999999","#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#C77CFF","#F8766D","#7CAE00"),max.words=as.numeric(input$adjust),title.size=2)
docs[[which(input$j==filenames)]][[5]] %>%
inner_join(get_sentiments("nrc")) %>%
count(word,sentiment,sort=TRUE) %>%
acast(word~sentiment,value.var="n",fill=0) %>%
comparison.cloud(colors=c("#999999","#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#C77CFF","#F8766D","#7CAE00"),max.words=as.numeric(input$adjust),title.size=2)
})
# Chunk 12
speech.res.word<-docs.res.word %>%
count(speech.num,word, sort = TRUE) %>%
ungroup()
speech.res.word<-left_join(speech.res.word,(speech.res.word%>%group_by(speech.num)%>%summarize(total=sum(n))))
speech.res.word<-speech.res.word %>% bind_tf_idf(word,speech.num,n)
plot.res <- speech.res.word %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
a<-ggplot(plot.res[1:20,], aes(word, tf_idf)) +
geom_bar(stat = "identity") +
labs(x = NULL, y = "tf-idf") +
coord_flip()
speech.nres.word<-docs.nres.word %>%
count(speech.num,word, sort = TRUE) %>%
ungroup()
speech.nres.word<-left_join(speech.nres.word,(speech.nres.word%>%group_by(speech.num)%>%summarize(total=sum(n))))
speech.nres.word<-speech.nres.word %>% bind_tf_idf(word,speech.num,n)
plot.nres <- speech.nres.word %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
b<-ggplot(plot.nres[1:20,], aes(word, tf_idf)) +
geom_bar(stat = "identity") +
labs(x = NULL, y = "tf-idf") +
coord_flip()
plot_grid(plotlist=list(a,b))
View(text.num)
dtms<-function(text){
corp<-Corpus(VectorSource(text))
dtm<-DocumentTermMatrix(corp)
fq<-colSums(as.matrix(dtm))
return(list(dtm=dtm,freq=fq))
}
dtms.list<-llply(docs,dtms)
dtms.list[[1]]
dtms.list[[1]]$freq
names(sort(dtms.list[[1]]$freq))
head(names(sort(dtms.list[[1]]$freq)),6)
dtms<-function(text){
corp<-Corpus(VectorSource(text))
corp<-tm_map(corp,removeNumbers)
corp<-tm_map(corp,removePunctuation)
corp<-tm_map(corp,removeWords,stopwords("english"))
corp<-tm_map(corp,stripWhitespace)
dtm<-DocumentTermMatrix(corp)
fq<-colSums(as.matrix(dtm))
return(list(dtm=dtm,freq=fq))
}
dtms.list<-llply(docs,dtms)
head(names(sort(dtms.list[[1]]$freq)),6)
kwords<-data.frame()
for (i in 1:58){
kwords<-rbind(head(names(sort(dtms.list[[i]]$freq)),16),kwords)
}
View(kwords)
kwords<-data.frame()
kwords<-rbind(head(names(sort(dtms.list[[1]]$freq)),16),kwords)
View(kwords)
kwords<-rbind(head(names(sort(dtms.list[[2]]$freq)),16),kwords)
View(kwords)
warnings(())
warnings(
)
text.num$word1<-NULL
View(text.num)
text.num$word1<-rep(NA,58)
View(text.num)
text.num$word2<-rep(NA,58)
text.num$word3<-rep(NA,58)
for (i in 1:58){
kwords<-head(names(sort(dtms.list[[i]]$freq)),3)
text.num$word1[i]<-kwords[1]
text.num$word2[i]<-kwords[2]
text.num$word3[i]<-kwords[3]
}
View(text.num)
?svm
install.packages("kernlab")
library(kernlab)
svm<-ksvm(text.num[whether.res,],text.num[!whether.res,],type="C-svc",kernel='vanilladot',C=100,scaled=c())
svm<-ksvm(text.num[whether.res,],text.num[!whether.res,],type="C-svc",C=100,scaled=c())
shiny::runApp('~/Documents/graduate/applied data science/Spr2017-proj2-grp7/doc/Yue Gao')
runApp('~/Documents/graduate/applied data science/Spr2017-proj2-grp7/app_kai')
runApp('~/Documents/graduate/applied data science/Spr2017-proj2-grp7/app_kai')
runApp('~/Documents/graduate/applied data science/Spr2017-proj2-grp7/doc/Yue Gao')
runApp('~/Documents/graduate/applied data science/Spr2017-proj2-grp7/app_kai')
runApp('~/Documents/graduate/applied data science/Spr2017-proj2-grp7/app_kai')
