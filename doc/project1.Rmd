---
title: "project1"
author: "Yaqin Li (yl3578)"
date: "2/1/2017"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Download and library packages

```{r , message=FALSE, warning=FALSE}
packages.used=c("tibble",
                "sentimentr", "dplyr",
                "tm",  "beeswarm","RColorBrewer",
                 "topicmodels","plyr","ggplot2","wordcloud","reshape2","tidytext","stringr","qdap","cowplot","tidyr")

packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))

if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}


library(tm)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(topicmodels)
library(reshape2)
library(tidytext)
library(stringr)
library(qdap)
library(beeswarm)
library(cowplot)
library(tidyr)
```

This notebook was prepared with the following environmental settings.

```{r}
print(R.version)
```

## Read txt data

```{r , warning=FALSE}
path<-file.path("..","data","InauguralSpeeches")
filenames<-dir(path)
speeches.number<-length(dir(path))
speeches.number

docs<-Corpus(DirSource(path))
head(summary(docs),3)

```


## Divide data in to two subdataset(recession and not recession)

```{r }
years<-read.csv("../data/InauguationDates.csv",header=TRUE,stringsAsFactors = FALSE)
years.name<-gsub("[ |.]","",years$PRESIDENT)
years.recession<-c(1825,1837,1847,1857,1866,1873,1882:1893,1920,1929:1933,1948:1949,1953:1954,1957:1958,1960:1961,1969:1970,1973:1975,1980:1982,1990:1991,2001:2002,2007:2009)

whether.res<-rep(FALSE,58)
for (i in 1:58) {
  n<-nchar(filenames[i])
  filenames1<-substr(filenames[i],6,n-6)
  j<-which(years.name==filenames1)
  time<-years[j,as.numeric(substr(filenames[i],n-4,n-4))+1]
  m<-nchar(time)
  if (sum(as.numeric(substr(time,m-3,m)) == years.recession) > 0) whether.res[i]<-TRUE
}
sum(whether.res)
```


## Function:count punctuations, numbers and certain words in the inauguralspeeches

```{r}
docs<-tm_map(docs,content_transformer(tolower))

text.count<-function(speeches){
  text<-speeches[[1]]
  punc<-length(gregexpr("[.|!|?|;]",text)[[1]])
  i<-length(gregexpr("i |me |myself |my |mine ",text)[[1]])
  we<-length(gregexpr("we |us |ourself|our |ours ",text)[[1]])/i
  modal<-length(gregexpr("will|can|shall|must",text)[[1]])/i
  return(list(sentence=punc,i=i,we=we,modal=modal))
}

docs<-tm_map(docs,removeNumbers)
docs<-tm_map(docs,stripWhitespace)

text.num<-llply(docs,text.count)
text.num<-ldply(text.num,unlist)
text.num$whether.res<-whether.res

beeswarm(sentence~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2, ylab="Number of sentences.")
boxplot(sentence~whether.res,data = text.num, add = T,
        names = c("",""), col="#0000ff22",outline=FALSE) 

beeswarm(we~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,ylab="the proportion of we to i")
boxplot(we~whether.res,data = text.num, add = T,
        names = c("",""), col="#0000ff22",outline=FALSE)  

beeswarm(modal~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,ylab="Number of sentences")
boxplot(we~whether.res,data = text.num, add = T,
        names = c("",""), col="#0000ff22",outline=FALSE)  

```

## Wordcloud+sentiment

```{r,warning=FALSE}
docs.res<-data.frame(stringsAsFactors = FALSE)
docs.nres<-data.frame(stringsAsFactors = FALSE)
for(i in 1:58){
  docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
  docs[[i]][[4]]<-word_count(docs[[i]][[3]])
  docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
  docs[[i]][[3]]$speech.num<-rep(i,nrow(docs[[i]][[3]]))
  docs[[i]][[5]]<-unnest_tokens(docs[[i]][[3]],word,text)
  if (whether.res[i]) docs.res<-rbind(docs.res,docs[[i]][[3]])
  else docs.nres<-rbind(docs.nres,docs[[i]][[3]])
}

docs.res.word<-unnest_tokens(docs.res,word,text)
docs.nres.word<-unnest_tokens(docs.nres,word,text)

par(mfrow=c(1,2))
docs.res.word %>%
  inner_join(get_sentiments("bing")) %>%
  count(word,sentiment,sort=TRUE) %>%
  acast(word~sentiment,value.var="n",fill=0) %>%
  comparison.cloud(colors=c("#E69F00", "#56B4E9"),max.words=100,title.size=2)
legend("topleft",legend="recession",bty="n",text.col=1)

docs.nres.word %>%
  inner_join(get_sentiments("bing")) %>%
  count(word,sentiment,sort=TRUE) %>%
  acast(word~sentiment,value.var="n",fill=0) %>%
  comparison.cloud(colors=c("#E69F00", "#56B4E9"),max.words=100,title.size=2)
legend("topleft",legend="not recession",bty="n",text.col=1)
```

```{r}
bingword.res<-docs.res.word %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()
bingword.nres<-docs.nres.word %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

a<-bingword.res %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment(recession)",
       x = NULL) +
  coord_flip()

b<-bingword.nres %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment( not recession)",
       x = NULL) +
  coord_flip()

plot_grid(plotlist=list(a,b),nrow=2)

```

```{r eruptions, echo=FALSE}
inputPanel(
  selectInput("i", label = "Speeches in the recession",
              choices = filenames[whether.res], selected = filenames[whether.res][1]),
  
  sliderInput("adjust", label = "number of word",
              min = 50, max = 150, value = 100, step = 10),
  
  selectInput("j", label = "Speeches not in the recession",
              choices = filenames[!whether.res], selected = filenames[!whether.res][1])
  
)

renderPlot({
  par(mfrow=c(1,2),mar = c(1,1,1,1))
  docs[[which(input$i==filenames)]][[5]] %>%
  inner_join(get_sentiments("nrc")) %>%
  count(word,sentiment,sort=TRUE) %>%
  acast(word~sentiment,value.var="n",fill=0) %>%
  comparison.cloud(colors=c("#999999","#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#C77CFF","#F8766D","#7CAE00"),max.words=as.numeric(input$adjust),title.size=2)
  
  docs[[which(input$j==filenames)]][[5]] %>%
  inner_join(get_sentiments("nrc")) %>%
  count(word,sentiment,sort=TRUE) %>%
  acast(word~sentiment,value.var="n",fill=0) %>%
  comparison.cloud(colors=c("#999999","#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#C77CFF","#F8766D","#7CAE00"),max.words=as.numeric(input$adjust),title.size=2)
  
})
```


##tf-idf

```{r}
speech.res.word<-docs.res.word %>%
  count(speech.num,word, sort = TRUE) %>%
  ungroup()
speech.res.word<-left_join(speech.res.word,(speech.res.word%>%group_by(speech.num)%>%summarize(total=sum(n))))

speech.res.word<-speech.res.word %>% bind_tf_idf(word,speech.num,n)
  
plot.res <- speech.res.word %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))

a<-ggplot(plot.res[1:20,], aes(word, tf_idf)) +
  geom_bar(stat = "identity") +
  labs(x = NULL, y = "tf-idf") +
  coord_flip()

speech.nres.word<-docs.nres.word %>%
  count(speech.num,word, sort = TRUE) %>%
  ungroup()
speech.nres.word<-left_join(speech.nres.word,(speech.nres.word%>%group_by(speech.num)%>%summarize(total=sum(n))))

speech.nres.word<-speech.nres.word %>% bind_tf_idf(word,speech.num,n)

plot.nres <- speech.nres.word %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))

b<-ggplot(plot.nres[1:20,], aes(word, tf_idf)) +
  geom_bar(stat = "identity") +
  labs(x = NULL, y = "tf-idf") +
  coord_flip()
  
plot_grid(plotlist=list(a,b))
```


## Topicmodelling:LDA

```{r}
docs<-tm_map(docs,removeWords,c(stopwords("english"),"us","will","can","shall","must","upon","may","people","great","states","one","let","government","nation","now","every","new"))
docs<-tm_map(docs,removePunctuation)

a<-1:58
docs.r<-docs[a[whether.res]]
docs.nr<-docs[a[!whether.res]]

dtmatrix.res<-DocumentTermMatrix(docs.r)

inaugu.r.lda<-LDA(dtmatrix.res,k=2)
inaugu.r.lda.td<-tidy(inaugu.r.lda)
inaugu.r.term<-inaugu.r.lda.td%>%
  group_by(topic)%>%
  top_n(10,beta)%>%
  ungroup()%>%
  arrange(topic,-beta)

inaugu.r.term %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

dtmatrix.nres<-DocumentTermMatrix(docs.nr)

inaugu.nr.lda<-LDA(dtmatrix.nres,k=2)
inaugu.nr.lda.td<-tidy(inaugu.nr.lda)
inaugu.nr.term<-inaugu.nr.lda.td%>%
  group_by(topic)%>%
  top_n(10,beta)%>%
  ungroup()%>%
  arrange(topic,-beta)

inaugu.nr.term %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

```

```{r}
beta_spread1 <- inaugu.r.lda.td %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))
head(beta_spread1)

beta_spread2 <- inaugu.nr.lda.td %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))
head(beta_spread2)
```

```{r}
inaugu.r_gamma<- tidy(inaugu.r.lda, matrix = "gamma")
```


